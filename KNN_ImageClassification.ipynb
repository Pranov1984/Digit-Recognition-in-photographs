{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=h5py.File('SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ds['X_train'][:]\n",
    "y_train = ds['y_train'][:]\n",
    "X_test = ds['X_test'][:]\n",
    "y_test = ds['y_test'][:]\n",
    "X_val = ds['X_val'][:]\n",
    "y_val = ds['y_val'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping X data: (n, 32, 32) => (n, 1024)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "# get the val data set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33600, 1024), (18000, 1024), (8400, 1024))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close this file\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89.9371,  93.7518, 102.0391, ..., 125.2774, 125.9784, 130.1521],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "X_val = X_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30694444444444446"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not very impressive accuracy and the time taken to complete the claculation is very high\n",
    "#Let's try to see if there is an optimal value of k that can give better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "List=list(np.arange(3,15))\n",
    "neigbors=list(filter(lambda x: x%2!=0,List))\n",
    "Accuracy=[]\n",
    "AUC_KNN=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on misclassification compariosn, optimal n: 3\n"
     ]
    }
   ],
   "source": [
    "for n in neigbors:\n",
    "    knn=KNeighborsClassifier(n_neighbors=n, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    acc=knn.score(X_test,y_test)\n",
    "    Accuracy.append(acc)\n",
    "    \n",
    "MissClassification=[1-x for x in Accuracy]\n",
    "MissClassification.index(min(MissClassification))\n",
    "print(\"Based on misclassification compariosn, optimal n: %i\" %neigbors[MissClassification.index(min(MissClassification))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e4bdd506a0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neigbors,MissClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like the increased value of k may give better accuracy as is evident from the graph above. Let's try out with k = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1688888888888889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=12, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worser score than before. Let's try with k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2001111111111111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=8, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slight improvement but worser than when k=5. Let's try k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2291111111111111"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=4, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting talos\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/df/c352679af3259829dafa7d55f2d3e9fca201c848351cb3c841a062df001c/talos-0.6.3.tar.gz\n",
      "Collecting wrangle (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/35/bc729e377417613f2d062a890faea5d649ef1a554df21499e9c3a4a5501a/wrangle-0.6.7.tar.gz\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from talos) (1.16.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from talos) (0.24.2)\n",
      "Requirement already satisfied: keras in c:\\users\\user\\anaconda3\\lib\\site-packages (from talos) (2.3.1)\n",
      "Collecting astetik (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/ba/f8622951da73d9b47b45bb847112c388651f9c6e413e712954f260301d9f/astetik-1.9.9.tar.gz\n",
      "Collecting sklearn (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from talos) (4.32.1)\n",
      "Collecting chances (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/d8/d61112d7476dc3074b855f1edd8556cde9b49b7106853f0b060109dd4c82/chances-0.1.9.tar.gz\n",
      "Collecting kerasplotlib (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/2e/b8628bfef6a817da9be863f650cf67187676b10d27d94b23f248da35d2b4/kerasplotlib-0.1.4.tar.gz\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from talos) (2.22.0)\n",
      "Collecting scipy==1.2 (from wrangle->talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/b8/800d98339427199305f8b4a7f02827ec9bfea438d677aecbe0bd297092d5/scipy-1.2.0-cp37-cp37m-win_amd64.whl (31.7MB)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\user\\anaconda3\\lib\\site-packages (from wrangle->talos) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->talos) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->talos) (2019.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->talos) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->talos) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->talos) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->talos) (5.1.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras->talos) (1.12.0)\n",
      "Collecting geonamescache (from astetik->talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/c1/efb823270c8526b2f4f3eb8c804c5a0a55277267ad2312f5eb47bd9cc370/geonamescache-1.1.0-py3-none-any.whl (830kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from sklearn->talos) (0.21.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->talos) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->talos) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->talos) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->talos) (1.24.2)\n",
      "Requirement already satisfied: patsy>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from statsmodels->wrangle->talos) (0.5.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->talos) (0.13.2)\n",
      "Building wheels for collected packages: talos, wrangle, astetik, sklearn, chances, kerasplotlib\n",
      "  Building wheel for talos (setup.py): started\n",
      "  Building wheel for talos (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\bb\\d7\\6b\\86fd8b1fc7cfbd2c54796412f86efb5fb6a3a5c734014f6a66\n",
      "  Building wheel for wrangle (setup.py): started\n",
      "  Building wheel for wrangle (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\bf\\1b\\50\\d0403ce6ef269e364894da7b50db68db14c4ac62c577561e2d\n",
      "  Building wheel for astetik (setup.py): started\n",
      "  Building wheel for astetik (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\ae\\70\\21\\c475cd079ec401dd6e1b9b1d42b4c38554ce12679bfb214aad\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\76\\03\\bb\\589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Building wheel for chances (setup.py): started\n",
      "  Building wheel for chances (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\75\\33\\46\\c871b94249bd57d17797d049b3dff8e3a09c315afb67eb14c6\n",
      "  Building wheel for kerasplotlib (setup.py): started\n",
      "  Building wheel for kerasplotlib (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\pip\\Cache\\wheels\\36\\6b\\4c\\e1fc6d7d8811940fbea1147b1519c7baa6933e4baeff904433\n",
      "Successfully built talos wrangle astetik sklearn chances kerasplotlib\n",
      "Installing collected packages: scipy, sklearn, wrangle, geonamescache, astetik, chances, kerasplotlib, talos\n",
      "  Found existing installation: scipy 1.2.1\n",
      "    Uninstalling scipy-1.2.1:\n",
      "      Successfully uninstalled scipy-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\~cipy\\\\integrate\\\\lsoda.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'talos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3bf072900deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtalos\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'talos'"
     ]
    }
   ],
   "source": [
    "import talos as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        output = np.dot(self.X, self.W) + self.b\n",
    "        return output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Rectified Linear Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y]+1e-16)\n",
    "        loss = np.sum(cross_entropy) / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we define the container NN class that enables the forward prop and backward propagation of the entire network. Note, how this class enables us to add layers of different types and also correctly pass gradients using the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc=CrossEntropy(), mode='train'):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)  + ((Lambda / (2 * y.shape[0])) * np.sum([np.sum(w**2) for w in self.params[0][0]]))\n",
    "        nextgrad = self.loss_func.backward(out,y) + ((Lambda/y.shape[0]) * np.sum([np.sum(w) for w in self.params[0][0]]))\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return p\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the update function (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = (mu * v[i]) - (learning_rate * g[i])\n",
    "            p[i] += v[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function which gives us the minibatches (both the datapoint and the corresponding label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None, Lambda=0, verb=True):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        # accuracy of model at end of epoch after all mini batch updates\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        y_train_pred = []\n",
    "        y_val_pred = []\n",
    "        y_train1 = []\n",
    "        y_vall = []\n",
    "        for ii in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[ii:ii + minibatch_size, : ]\n",
    "            y_tr = y_train[ii:ii + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for ii in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[ii:ii + minibatch_size, : ]\n",
    "            y_va = y_val[ii:ii + minibatch_size,]\n",
    "            y_vall = np.append(y_vall, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
    "        \n",
    "        ## weights\n",
    "        w = np.array(net.params[0][0])\n",
    "        \n",
    "        ## adding regularization to cost\n",
    "        mean_train_loss = (sum(loss_batch) / float(len(loss_batch)))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        if verb:\n",
    "            if i%50==0:\n",
    "                print(\"Epoch {3}/{4}: Loss = {0} | Training Accuracy = {1}\".format(mean_train_loss, train_acc, val_acc, i, epoch))\n",
    "    return net, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for checking Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    count = 0\n",
    "    for i,j in zip(y_true, y_pred):\n",
    "        if int(i)==j:\n",
    "            count +=1\n",
    "    return float(count)/float(len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattening and normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 32, 32), (18000, 32, 32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "#Flattenning of the features sets\n",
    "\n",
    "X_train = X_train.reshape(42000, 1024)\n",
    "print (X_train.shape)\n",
    "X_test = X_test.reshape(18000, 1024)\n",
    "print( X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize inputs\n",
    "X_train = (X_train-np.mean(X_train))/np.std(X_train)\n",
    "X_test = (X_test-np.mean(X_test))/np.std(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for training the model and testing it on the test data for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "## input size\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 10\n",
    "    output_nodes = 10\n",
    "\n",
    "    ## define neural net\n",
    "    nn = NN()\n",
    "    nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "\n",
    "    nn, val_acc = sgd(nn, X_train , y_train, minibatch_size=1000, epoch=iterations, learning_rate=learning_rate,\\\n",
    "                      X_val=X_test, y_val=y_test, Lambda=Lambda, verb=verb)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Check that the loss is reasonable : Disable the regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1: Loss = 2.3218666994333788 | Training Accuracy = 0.09892857142857144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09844444444444445"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "train_and_test_loop(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10 classes in the target variable and hence at random accuracy is expected to be around 100/10 i.e. value at random. We have it close to 10%. Hence it's good to go.\n",
    "\n",
    "Loss also makes sense becasue the value of softax is .1 for all labels and negative log of .1 is around 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1: Loss = 4.228179270459172e+17 | Training Accuracy = 0.09840476190476191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09816666666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 1e3\n",
    "train_and_test_loop(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huge Loss which is what is expected since the accuracy is not poor and hence loss should be very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, lets overfit to a small subset of our dataset, in this case 20 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train[0:20]\n",
    "y_train_subset = y_train[0:20]\n",
    "\n",
    "X_train = X_train_subset\n",
    "y_train = y_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2000: Loss = 2.3875268479239895 | Training Accuracy = 0.15\n",
      "Epoch 50/2000: Loss = 2.090608937656948 | Training Accuracy = 0.35\n",
      "Epoch 100/2000: Loss = 1.8911842115878268 | Training Accuracy = 0.55\n",
      "Epoch 150/2000: Loss = 1.7469563229405671 | Training Accuracy = 0.55\n",
      "Epoch 200/2000: Loss = 1.633689919590148 | Training Accuracy = 0.65\n",
      "Epoch 250/2000: Loss = 1.5391738950086853 | Training Accuracy = 0.7\n",
      "Epoch 300/2000: Loss = 1.457226872576279 | Training Accuracy = 0.75\n",
      "Epoch 350/2000: Loss = 1.3844583896404878 | Training Accuracy = 0.8\n",
      "Epoch 400/2000: Loss = 1.3188260562149068 | Training Accuracy = 0.85\n",
      "Epoch 450/2000: Loss = 1.2589951563462596 | Training Accuracy = 0.85\n",
      "Epoch 500/2000: Loss = 1.2040342343174166 | Training Accuracy = 0.85\n",
      "Epoch 550/2000: Loss = 1.1532580908690415 | Training Accuracy = 0.85\n",
      "Epoch 600/2000: Loss = 1.1061407606062061 | Training Accuracy = 0.85\n",
      "Epoch 650/2000: Loss = 1.062264331674009 | Training Accuracy = 0.85\n",
      "Epoch 700/2000: Loss = 1.0212873141876748 | Training Accuracy = 0.85\n",
      "Epoch 750/2000: Loss = 0.982924238194593 | Training Accuracy = 0.85\n",
      "Epoch 800/2000: Loss = 0.9469319989924673 | Training Accuracy = 0.9\n",
      "Epoch 850/2000: Loss = 0.9131004227276165 | Training Accuracy = 0.95\n",
      "Epoch 900/2000: Loss = 0.8812455667965828 | Training Accuracy = 0.95\n",
      "Epoch 950/2000: Loss = 0.8512048468270608 | Training Accuracy = 0.95\n",
      "Epoch 1000/2000: Loss = 0.8228334145094001 | Training Accuracy = 0.95\n",
      "Epoch 1050/2000: Loss = 0.7960014094968778 | Training Accuracy = 0.95\n",
      "Epoch 1100/2000: Loss = 0.7705918320595371 | Training Accuracy = 0.95\n",
      "Epoch 1150/2000: Loss = 0.7464988624769666 | Training Accuracy = 0.95\n",
      "Epoch 1200/2000: Loss = 0.7236265057305087 | Training Accuracy = 0.95\n",
      "Epoch 1250/2000: Loss = 0.7018874758956015 | Training Accuracy = 0.95\n",
      "Epoch 1300/2000: Loss = 0.6812022596044729 | Training Accuracy = 0.95\n",
      "Epoch 1350/2000: Loss = 0.6614983155847216 | Training Accuracy = 0.95\n",
      "Epoch 1400/2000: Loss = 0.6427093797946922 | Training Accuracy = 0.95\n",
      "Epoch 1450/2000: Loss = 0.6247748545299913 | Training Accuracy = 0.95\n",
      "Epoch 1500/2000: Loss = 0.6076392660804036 | Training Accuracy = 0.95\n",
      "Epoch 1550/2000: Loss = 0.5912517798094005 | Training Accuracy = 0.95\n",
      "Epoch 1600/2000: Loss = 0.5755657644577531 | Training Accuracy = 0.95\n",
      "Epoch 1650/2000: Loss = 0.5605383994484339 | Training Accuracy = 1.0\n",
      "Epoch 1700/2000: Loss = 0.5461303202944514 | Training Accuracy = 1.0\n",
      "Epoch 1750/2000: Loss = 0.5323052981029052 | Training Accuracy = 1.0\n",
      "Epoch 1800/2000: Loss = 0.5190299497802027 | Training Accuracy = 1.0\n",
      "Epoch 1850/2000: Loss = 0.5062734759788013 | Training Accuracy = 1.0\n",
      "Epoch 1900/2000: Loss = 0.49400742415273413 | Training Accuracy = 1.0\n",
      "Epoch 1950/2000: Loss = 0.4822054743501229 | Training Accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12166666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "Lambda = 0\n",
    "train_and_test_loop(2000, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfitting achieved as can be seen with 100% training accuracy and very poor validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the original dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "ds=h5py.File('SVHN_single_grey1.h5','r')\n",
    "X_train = ds['X_train'][:]\n",
    "y_train = ds['y_train'][:]\n",
    "X_test = ds['X_test'][:]\n",
    "y_test = ds['y_test'][:]\n",
    "\n",
    "X_train = X_train.reshape(42000, 1024)\n",
    "print (X_train.shape)\n",
    "X_test = X_test.reshape(18000, 1024)\n",
    "print( X_test.shape)\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = (X_test/255)\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with small regularization and find learning rate that makes the loss go down.\n",
    "\n",
    "    - we start with Lambda(small regularization) = 1e-5\n",
    "    - we start with a small learning rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500: Loss = 2.304688342459408 | Training Accuracy = 0.10578571428571429\n",
      "Epoch 50/500: Loss = 2.284384008133931 | Training Accuracy = 0.17373809523809525\n",
      "Epoch 100/500: Loss = 2.2743549279196658 | Training Accuracy = 0.18761904761904763\n",
      "Epoch 150/500: Loss = 2.2679810627341945 | Training Accuracy = 0.1944047619047619\n",
      "Epoch 200/500: Loss = 2.2635346119606483 | Training Accuracy = 0.19890476190476192\n",
      "Epoch 250/500: Loss = 2.2602410398791113 | Training Accuracy = 0.20211904761904761\n",
      "Epoch 300/500: Loss = 2.257689566761467 | Training Accuracy = 0.20426190476190476\n",
      "Epoch 350/500: Loss = 2.255641103333613 | Training Accuracy = 0.2068809523809524\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-d25a6ead286a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_and_test_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-b5770c3f6d9b>\u001b[0m in \u001b[0;36mtrain_and_test_loop\u001b[1;34m(iterations, lr, Lambda, verb)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     nn, val_acc = sgd(nn, X_train , y_train, minibatch_size=1000, epoch=iterations, learning_rate=learning_rate,\\\n\u001b[1;32m---> 19\u001b[1;33m                       X_val=X_test, y_val=y_test, Lambda=Lambda, verb=verb)\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-62e5c5deca26>\u001b[0m in \u001b[0;36msgd\u001b[1;34m(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu, X_val, y_val, Lambda, verb)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# iterate over mini batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mX_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mini\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mini\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mloss_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvelocity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-5c21a33b14ba>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mnextgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-5c21a33b14ba>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mnextgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2076\u001b[1;33m                           initial=initial)\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[0;32m     71\u001b[0m                   if v is not np._NoValue}\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "Lambda = 1e-5\n",
    "train_and_test_loop(500, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss barely changing. Learning rate is probably too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now lets try a (larger) learning rate 1e6. What could possibly go wrong?¶\n",
    "Learning rate lr = 1e3\n",
    "Regularization lambda = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500: Loss = 364875908.40788776 | Training Accuracy = 0.11719047619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500: Loss = nan | Training Accuracy = 0.09966666666666667\n",
      "Epoch 100/500: Loss = nan | Training Accuracy = 0.09966666666666667\n",
      "Epoch 150/500: Loss = nan | Training Accuracy = 0.09966666666666667\n",
      "Epoch 200/500: Loss = nan | Training Accuracy = 0.09966666666666667\n",
      "Epoch 250/500: Loss = nan | Training Accuracy = 0.09966666666666667\n",
      "Epoch 300/500: Loss = nan | Training Accuracy = 0.09966666666666667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-80a04a6dd95e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_and_test_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-b5770c3f6d9b>\u001b[0m in \u001b[0;36mtrain_and_test_loop\u001b[1;34m(iterations, lr, Lambda, verb)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     nn, val_acc = sgd(nn, X_train , y_train, minibatch_size=1000, epoch=iterations, learning_rate=learning_rate,\\\n\u001b[1;32m---> 19\u001b[1;33m                       X_val=X_test, y_val=y_test, Lambda=Lambda, verb=verb)\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-62e5c5deca26>\u001b[0m in \u001b[0;36msgd\u001b[1;34m(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu, X_val, y_val, Lambda, verb)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mX_mini_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mini_val\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatches_val\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_mini\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mval_loss_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-5c21a33b14ba>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mnextgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-cf309c47e8cb>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0my_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e3\n",
    "Lambda = 1e-5\n",
    "train_and_test_loop(150, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Loss exploding. Learning rate is too high. \n",
    "Cost is very high. Always means high learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to train now with a value of learning rate between 1e-3 and 1e3 learning rate = 1e1 regularization remains the small, lambda = 1e-5\n",
    "\n",
    "- learning rate = 1e2\n",
    "- regularization remains the small, lambda = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100: Loss = 32.02170561745086 | Training Accuracy = 0.11766666666666667\n",
      "Epoch 50/100: Loss = 1.5239775629500174e+229 | Training Accuracy = 0.09966666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in square\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10077777777777777"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e2\n",
    "Lambda = 1e-5\n",
    "train_and_test_loop(300, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss decreased but the training error decreased as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "Cross validation Strategy\n",
    "Do coarse -> fine cross-validation in stages\n",
    "\n",
    "First stage: only a few epochs to get rough idea of what params work\n",
    "\n",
    "Second stage: longer running time, finer search\n",
    "… (repeat as necessary)\n",
    "\n",
    "Tip for detecting explosions in the solver:\n",
    "If the cost is ever > 3 * original cost, break out early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 1/100: Best_val_acc: 0.11805555555555555, lr: 7.358299496941898, Lambda: 1.3621490977462332e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: overflow encountered in square\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in subtract\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 2/100: Best_val_acc: 0.10077777777777777, lr: 0.0021628734188058065, Lambda: 5.988866557494161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in add\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 3/100: Best_val_acc: 0.10077777777777777, lr: 0.6635189124484699, Lambda: 0.7536146579457659\n",
      "\n",
      "Try 4/100: Best_val_acc: 0.19461111111111112, lr: 0.006330189976273386, Lambda: 0.06901051587315007\n",
      "\n",
      "Try 5/100: Best_val_acc: 0.10077777777777777, lr: 0.22129214054648036, Lambda: 1476.2956223719848\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 6/100: Best_val_acc: 0.10077777777777777, lr: 1.2228834900371965, Lambda: 29975.85937016018\n",
      "\n",
      "Try 7/100: Best_val_acc: 0.12472222222222222, lr: 0.09516776124685365, Lambda: 0.0002820060646530451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in add\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 8/100: Best_val_acc: 0.10077777777777777, lr: 0.7111856183857013, Lambda: 51.61743620698368\n",
      "\n",
      "Try 9/100: Best_val_acc: 0.21366666666666667, lr: 0.0012697061581887997, Lambda: 0.00012378876176963096\n",
      "\n",
      "Try 10/100: Best_val_acc: 0.10077777777777777, lr: 3.913048886035498, Lambda: 0.0005598391590978223\n",
      "\n",
      "Try 11/100: Best_val_acc: 0.10077777777777777, lr: 0.11098144550727576, Lambda: 0.016425884121535464\n",
      "\n",
      "Try 12/100: Best_val_acc: 0.19455555555555556, lr: 0.007333807276387773, Lambda: 1.0385738790326014e-05\n",
      "\n",
      "Try 13/100: Best_val_acc: 0.10077777777777777, lr: 0.30967596104631956, Lambda: 127.40604729639442\n",
      "\n",
      "Try 14/100: Best_val_acc: 0.10077777777777777, lr: 7.724947664652395, Lambda: 0.008716760384626302\n",
      "\n",
      "Try 15/100: Best_val_acc: 0.10077777777777777, lr: 3.9039776613821493, Lambda: 0.0006897794226213421\n",
      "\n",
      "Try 16/100: Best_val_acc: 0.10077777777777777, lr: 0.45817865716997697, Lambda: 3657.98840456637\n",
      "\n",
      "Try 17/100: Best_val_acc: 0.1106111111111111, lr: 1.3932142901292008, Lambda: 3.3950888295762534e-05\n",
      "\n",
      "Try 18/100: Best_val_acc: 0.10077777777777777, lr: 0.11344864667174848, Lambda: 1.5728115388841164\n",
      "\n",
      "Try 19/100: Best_val_acc: 0.10077777777777777, lr: 0.005424056197066919, Lambda: 0.34848394425091966\n",
      "\n",
      "Try 20/100: Best_val_acc: 0.10077777777777777, lr: 1.1442623000555756, Lambda: 0.008466830552868117\n",
      "\n",
      "Try 21/100: Best_val_acc: 0.10077777777777777, lr: 0.04539007173136485, Lambda: 0.2816807796943718\n",
      "\n",
      "Try 22/100: Best_val_acc: 0.1126111111111111, lr: 1.74240618031398, Lambda: 0.00013075847644489729\n",
      "\n",
      "Try 23/100: Best_val_acc: 0.10077777777777777, lr: 0.1708949829607397, Lambda: 6.058746503728482\n",
      "\n",
      "Try 24/100: Best_val_acc: 0.10077777777777777, lr: 0.0039650453562807275, Lambda: 989.5519256665453\n",
      "\n",
      "Try 25/100: Best_val_acc: 0.12083333333333333, lr: 0.5035007622558866, Lambda: 0.0008296230150678046\n",
      "\n",
      "Try 26/100: Best_val_acc: 0.10077777777777777, lr: 5.246699199423672, Lambda: 0.00020614184733984788\n",
      "\n",
      "Try 27/100: Best_val_acc: 0.10077777777777777, lr: 0.24093023867123312, Lambda: 0.5854053222135696\n",
      "\n",
      "Try 28/100: Best_val_acc: 0.10077777777777777, lr: 0.0022430925789993614, Lambda: 8568.95362359573\n",
      "\n",
      "Try 29/100: Best_val_acc: 0.12088888888888889, lr: 0.054195671402129816, Lambda: 3.212436684781396e-05\n",
      "\n",
      "Try 30/100: Best_val_acc: 0.10077777777777777, lr: 0.0230967581360152, Lambda: 1.7923091239035738\n",
      "\n",
      "Try 31/100: Best_val_acc: 0.10077777777777777, lr: 0.06860159051071796, Lambda: 0.01250252634211026\n",
      "\n",
      "Try 32/100: Best_val_acc: 0.17272222222222222, lr: 0.02422916029339754, Lambda: 0.0006572725532853108\n",
      "\n",
      "Try 33/100: Best_val_acc: 0.10077777777777777, lr: 0.0024487042017755332, Lambda: 50.56329946152471\n",
      "\n",
      "Try 34/100: Best_val_acc: 0.10077777777777777, lr: 0.4199603181267112, Lambda: 0.734060667491689\n",
      "\n",
      "Try 35/100: Best_val_acc: 0.10077777777777777, lr: 7.788623477144757, Lambda: 0.4237573645725584\n",
      "\n",
      "Try 36/100: Best_val_acc: 0.11433333333333333, lr: 0.41184209276513534, Lambda: 2.5131714233812065e-05\n",
      "\n",
      "Try 37/100: Best_val_acc: 0.10077777777777777, lr: 0.03035962870779662, Lambda: 0.05955296760623934\n",
      "\n",
      "Try 38/100: Best_val_acc: 0.10077777777777777, lr: 8.464319461245397, Lambda: 65684.33484088969\n",
      "\n",
      "Try 39/100: Best_val_acc: 0.10077777777777777, lr: 0.4929469724605083, Lambda: 2445.5533792121223\n",
      "\n",
      "Try 40/100: Best_val_acc: 0.10077777777777777, lr: 2.3936676708356805, Lambda: 0.01691498136165696\n",
      "\n",
      "Try 41/100: Best_val_acc: 0.10077777777777777, lr: 2.203564144882217, Lambda: 47.793142579844485\n",
      "\n",
      "Try 42/100: Best_val_acc: 0.10077777777777777, lr: 1.613330415767877, Lambda: 0.15901655878580565\n",
      "\n",
      "Try 43/100: Best_val_acc: 0.10077777777777777, lr: 5.6785258486191115, Lambda: 1.3990660126991004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in multiply\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 44/100: Best_val_acc: 0.10077777777777777, lr: 4.001565382887356, Lambda: 1079.0695774160072\n",
      "\n",
      "Try 45/100: Best_val_acc: 0.10077777777777777, lr: 3.009420954938155, Lambda: 1.7956431223024025\n",
      "\n",
      "Try 46/100: Best_val_acc: 0.10077777777777777, lr: 0.004893474309564801, Lambda: 4858.091314307924\n",
      "\n",
      "Try 47/100: Best_val_acc: 0.10077777777777777, lr: 2.4693969198869774, Lambda: 3211.0071716963776\n",
      "\n",
      "Try 48/100: Best_val_acc: 0.10077777777777777, lr: 0.014152536501728867, Lambda: 1364.497047152505\n",
      "\n",
      "Try 49/100: Best_val_acc: 0.10077777777777777, lr: 0.016339934538213037, Lambda: 7.105761559709397\n",
      "\n",
      "Try 50/100: Best_val_acc: 0.10077777777777777, lr: 6.173299105918578, Lambda: 0.0019106511125873448\n",
      "\n",
      "Try 51/100: Best_val_acc: 0.10077777777777777, lr: 0.6421105107224735, Lambda: 227.1313154389455\n",
      "\n",
      "Try 52/100: Best_val_acc: 0.1825, lr: 0.014171229284092791, Lambda: 7.162198573376379e-05\n",
      "\n",
      "Try 53/100: Best_val_acc: 0.1205, lr: 0.19248596244989932, Lambda: 0.0008442118762514482\n",
      "\n",
      "Try 54/100: Best_val_acc: 0.10077777777777777, lr: 3.1554945135957118, Lambda: 0.0017330379572892169\n",
      "\n",
      "Try 55/100: Best_val_acc: 0.10077777777777777, lr: 0.6154924765285907, Lambda: 0.008675085963190362\n",
      "\n",
      "Try 56/100: Best_val_acc: 0.10077777777777777, lr: 0.016129410458534537, Lambda: 0.07154910689593184\n",
      "\n",
      "Try 57/100: Best_val_acc: 0.10077777777777777, lr: 0.003785563414587739, Lambda: 1.9391013894621116\n",
      "\n",
      "Try 58/100: Best_val_acc: 0.10077777777777777, lr: 0.004220817073437836, Lambda: 1713.0844961180296\n",
      "\n",
      "Try 59/100: Best_val_acc: 0.12555555555555556, lr: 1.5827209026854259, Lambda: 7.151194813148195e-05\n",
      "\n",
      "Try 60/100: Best_val_acc: 0.10077777777777777, lr: 0.005566917341076745, Lambda: 0.726180044232914\n",
      "\n",
      "Try 61/100: Best_val_acc: 0.10077777777777777, lr: 0.030264876703218292, Lambda: 3833.5503990045195\n",
      "\n",
      "Try 62/100: Best_val_acc: 0.11972222222222222, lr: 5.98930420209006, Lambda: 2.0808286673690487e-05\n",
      "\n",
      "Try 63/100: Best_val_acc: 0.11727777777777777, lr: 0.6098461003603052, Lambda: 9.448269771443353e-05\n",
      "\n",
      "Try 64/100: Best_val_acc: 0.10077777777777777, lr: 1.9588689231464766, Lambda: 902.4978523517012\n",
      "\n",
      "Try 65/100: Best_val_acc: 0.10077777777777777, lr: 0.14551007715042358, Lambda: 23815.687041245325\n",
      "\n",
      "Try 66/100: Best_val_acc: 0.10077777777777777, lr: 0.22308917271458611, Lambda: 174.09824326681638\n",
      "\n",
      "Try 67/100: Best_val_acc: 0.10077777777777777, lr: 0.004200554197778213, Lambda: 33.94002634507141\n",
      "\n",
      "Try 68/100: Best_val_acc: 0.10077777777777777, lr: 0.1381276732251363, Lambda: 36.579929398136365\n",
      "\n",
      "Try 69/100: Best_val_acc: 0.10077777777777777, lr: 0.13543956106317462, Lambda: 574.8903145533001\n",
      "\n",
      "Try 70/100: Best_val_acc: 0.17544444444444443, lr: 0.012748122698443384, Lambda: 7.81136905523083e-05\n",
      "\n",
      "Try 71/100: Best_val_acc: 0.10077777777777777, lr: 0.023349414372197088, Lambda: 1.1150664076096009\n",
      "\n",
      "Try 72/100: Best_val_acc: 0.10077777777777777, lr: 9.681632442092548, Lambda: 1.5086788600072591\n",
      "\n",
      "Try 73/100: Best_val_acc: 0.2106111111111111, lr: 0.0035714495839294117, Lambda: 0.003793044299420109\n",
      "\n",
      "Try 74/100: Best_val_acc: 0.10077777777777777, lr: 0.04125307577272089, Lambda: 223.66663306585409\n",
      "\n",
      "Try 75/100: Best_val_acc: 0.10077777777777777, lr: 0.284626021027494, Lambda: 0.0011892609760972542\n",
      "\n",
      "Try 76/100: Best_val_acc: 0.10077777777777777, lr: 1.3899301851524477, Lambda: 58.71494449854059\n",
      "\n",
      "Try 77/100: Best_val_acc: 0.2111111111111111, lr: 0.0026578492695379296, Lambda: 0.00014229915171133363\n",
      "\n",
      "Try 78/100: Best_val_acc: 0.10611111111111111, lr: 1.9915709979856158, Lambda: 1.9536256353724785e-05\n",
      "\n",
      "Try 79/100: Best_val_acc: 0.19833333333333333, lr: 0.011178206124426672, Lambda: 5.004492242037718e-05\n",
      "\n",
      "Try 80/100: Best_val_acc: 0.12566666666666668, lr: 4.008316518961383, Lambda: 4.1054893952233646e-05\n",
      "\n",
      "Try 81/100: Best_val_acc: 0.10916666666666666, lr: 2.5757175555013783, Lambda: 2.9261833669841798e-05\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-d38a94087a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mLambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_test_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-b5770c3f6d9b>\u001b[0m in \u001b[0;36mtrain_and_test_loop\u001b[1;34m(iterations, lr, Lambda, verb)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     nn, val_acc = sgd(nn, X_train , y_train, minibatch_size=1000, epoch=iterations, learning_rate=learning_rate,\\\n\u001b[1;32m---> 19\u001b[1;33m                       X_val=X_test, y_val=y_test, Lambda=Lambda, verb=verb)\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-62e5c5deca26>\u001b[0m in \u001b[0;36msgd\u001b[1;34m(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu, X_val, y_val, Lambda, verb)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0my_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mii\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0my_train1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-5c21a33b14ba>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-5c21a33b14ba>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-ae6fed8f64ca>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,100):\n",
    "    lr = math.pow(10, np.random.uniform(-3.0, 1.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,5))\n",
    "    best_acc = train_and_test_loop(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
